{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T10:19:45.853036Z",
     "start_time": "2020-02-06T10:19:45.466956Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T12:23:14.725459Z",
     "start_time": "2020-02-06T12:23:14.601517Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = np.array\n",
    "costs = []\n",
    "alpha = 0.01\n",
    "\n",
    "class LinearReg(object):\n",
    "    def __init__(self, optim:str = \"grad\"):\n",
    "        super(LinearReg, self).__init__()\n",
    "        if optim == \"grad\":\n",
    "            pass\n",
    "            #self.fit = self.fit_grad\n",
    "        elif optim == \"ols\":\n",
    "            pass\n",
    "            #self.fit = self.fit_ols\n",
    "        else:\n",
    "            raise Exception(\"Argument fit should be either ols or grad\")\n",
    "\n",
    "@njit\n",
    "def forward(X:arr, W: arr, b:arr) -> arr:\n",
    "    return np.dot(X,W) + b\n",
    "\n",
    "@njit\n",
    "def loss(y:arr, y_hat:arr) -> np.float:\n",
    "    return np.mean((y-y_hat)**2)\n",
    "\n",
    "@njit\n",
    "def get_grads(X: arr, y: arr, y_hat: arr) -> Tuple[np.float, arr]:\n",
    "    b_hat_d = -2 * (y-y_hat).mean()\n",
    "    W_hat_d = -2 * np.dot((y-y_hat), X)  / y.shape[0]    \n",
    "    return b_hat_d, W_hat_d\n",
    "\n",
    "@njit\n",
    "def update_params(W_hat:arr, b_hat:np.float, W_hat_d: arr, b_hat_d: np.float, alpha: np.float) -> Tuple[arr]:\n",
    "    b_hat -= b_hat_d * alpha\n",
    "    W_hat -= W_hat_d * alpha\n",
    "    return b_hat, W_hat\n",
    "\n",
    "X = np.random.normal(size=(1000, 10))\n",
    "W = np.array([0.1, 0.2, -0.1, 0.2, 0.1, 0.1, 0.2, -0.1, 0.2, 0.1])\n",
    "b = 0.5\n",
    "y = np.dot(X,W) + b\n",
    "\n",
    "\n",
    "@njit\n",
    "def fit_grad(X, y, iterations: int = 100000):\n",
    "    costs = []\n",
    "    W_hat = np.random.randn(X.shape[1])\n",
    "    b_hat = np.random.rand()\n",
    "    for iteration in range(iterations):\n",
    "        y_hat = forward(X, W_hat, b_hat)\n",
    "        cost = loss(y, y_hat)\n",
    "        costs.append(cost)\n",
    "        b_hat_d, W_hat_d = get_grads(X, y, y_hat)\n",
    "        b_hat, W_hat = update_params(W_hat, b_hat, W_hat_d, b_hat_d, alpha)\n",
    "        if (cost > costs[-1]) or (np.round(cost, 5) <= 0.0001):\n",
    "            break\n",
    "\n",
    "    return W_hat, b_hat, y_hat, costs\n",
    "weights, bias, preds, loss = fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
